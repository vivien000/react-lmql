{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An OpenAPI planner with LMQL and Langchain\n",
    "\n",
    "Directly inspired by the Langchain [tutorial](https://python.langchain.com/en/latest/modules/agents/toolkits/examples/openapi.html) on OpenAPI agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = # Add your OpenAI API key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval of the Spotify OpenAPI specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-25 00:37:31--  https://raw.githubusercontent.com/APIs-guru/openapi-directory/main/APIs/spotify.com/1.0.0/openapi.yaml\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 289324 (283K) [text/plain]\r\n",
      "Saving to: ‘openapi.yaml’\r\n",
      "\r\n",
      "openapi.yaml        100%[===================>] 282.54K  --.-KB/s    in 0.007s  \r\n",
      "\r\n",
      "2023-04-25 00:37:31 (40.0 MB/s) - ‘openapi.yaml’ saved [289324/289324]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/APIs-guru/openapi-directory/main/APIs/spotify.com/1.0.0/openapi.yaml\n",
    "!mv openapi.yaml spotify_openapi.yaml\n",
    "\n",
    "import yaml\n",
    "from langchain.agents.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "\n",
    "with open(\"spotify_openapi.yaml\") as f:\n",
    "    raw_spotify_api_spec = yaml.load(f, Loader=yaml.Loader)\n",
    "spotify_api_spec = reduce_openapi_spec(raw_spotify_api_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of the OpenAI planner agent in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.agents.agent_toolkits.openapi.planner_prompt import API_PLANNER_PROMPT\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0.0)\n",
    "\n",
    "endpoint_descriptions = [\n",
    "    f\"{name}\\n{description}\\n\" for name, description, _ in spotify_api_spec.endpoints\n",
    "]\n",
    "\n",
    "endpoint_names = set(name for name, _, _ in spotify_api_spec.endpoints)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=API_PLANNER_PROMPT,\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"endpoints\": \"- \" + \"- \".join(endpoint_descriptions)},\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. GET /search to search for the album Kind of Blue\n",
      "2. GET /albums/{id} to get the album's id\n",
      "3. GET /albums/{id}/tracks to get the tracks from the album\n",
      "4. GET /me to get the user's id\n",
      "5. POST /users/{id}/playlists to create a playlist with the name \"Machine Blues\"\n",
      "6. POST /playlists/{playlist_id}/tracks to add the first track from the album to the playlist\n"
     ]
    }
   ],
   "source": [
    "query = \"make me a playlist with the first song from kind of blue. call it machine blues.\"\n",
    "result = chain(query)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suggested in the Langchain tutorial, `text-davinci-003` struggles with this task. Here we see that an endpoint mentioned in the plan is invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POST /users/{id}/playlists']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_invalid_endpoints(s):\n",
    "    result = []\n",
    "    pattern = r\"\\b(GET|POST|PATCH|DELETE)\\s+(/\\S+)*\"\n",
    "    matches = re.findall(pattern, s)\n",
    "    for x, y in matches:\n",
    "        endpoint = f\"{x} {y}\"\n",
    "        if endpoint not in endpoint_names:\n",
    "            result.append(endpoint)\n",
    "    return result\n",
    "\n",
    "get_invalid_endpoints(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of an OpenAI planner agent in LMQL, with additional constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmql\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "@lmql.query\n",
    "async def plan(query, endpoint_names):\n",
    "    '''\n",
    "    argmax(max_len=4096)\n",
    "        \"{prompt.format(query=query)} \"\n",
    "        for i in range(1, 8):\n",
    "            \"{i}. [ENDPOINT] [PURPOSE]\"\n",
    "            if PURPOSE[-1] != \"\\n\":\n",
    "                break\n",
    "    from\n",
    "        \"openai/text-davinci-003\"\n",
    "    where\n",
    "        ENDPOINT in set(endpoint_names) and\n",
    "        STOPS_AT(PURPOSE, \"\\n\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the LMQL agent, the plan doesn't include any invalid endpoint (it's however not correct because it doesn't get the user id with `GET /me` before creating the playlist...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GET /search  with a query param to search for the album \"Kind of Blue\"\n",
      "2. GET /albums/{id}/tracks  to get the track list for the album\n",
      "3. GET /tracks/{id}  to get the track information for the first track\n",
      "4. POST /users/{user_id}/playlists  to create a new playlist\n",
      "5. POST /users/{user_id}/playlists  to add the track to the playlist\n",
      "6. POST /playlists/{playlist_id}/tracks  to add the track to the playlist\n",
      "7. POST /playlists/{playlist_id}/tracks  to rename the playlist to \"Machine Blues\"\n"
     ]
    }
   ],
   "source": [
    "query = \"make me a playlist with the first song from kind of blue. call it machine blues.\"\n",
    "result_lmql = await plan(query, endpoint_names)\n",
    "\n",
    "plan = result_lmql[0].prompt.split(\"Plan: \")[-1]\n",
    "print(plan)\n",
    "invalid = get_invalid_endpoints(plan)\n",
    "if len(invalid) > 0:\n",
    "    print(\", \".join(invalid))"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1681503907554,
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env llm)",
   "language": "python",
   "name": "py-dku-venv-llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "modifiedBy": "admin",
  "tags": [],
  "versionNumber": 1
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
